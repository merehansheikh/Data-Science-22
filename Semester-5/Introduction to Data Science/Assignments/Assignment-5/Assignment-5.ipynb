{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario\n",
    "*You are a data analyst for a retail company. Your task is to analyze customer and sales data to generate meaningful insights while handling real-world data issues.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Load the given datasets into Pandas DataFrames. Inspect the datasets and perform the following:\n",
    "* Display the first few rows of each dataset. \n",
    "* Show the total number of rows and columns. \n",
    "* Check for missing values in each dataset and handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of customer data:\n",
      "   CustomerID  Age         City\n",
      "0           1   22     New York\n",
      "1           2   23  Los Angeles\n",
      "2           3   24      Chicago\n",
      "3           4   25      Houston\n",
      "4           5   26      Phoenix\n",
      "\n",
      "First few rows of sales data:\n",
      "   SaleID  CustomerID     Product  Amount\n",
      "0     101           1      Laptop     200\n",
      "1     102           2  Smartphone     500\n",
      "2     103           3      Tablet     800\n",
      "3     104           4  Headphones    1100\n",
      "4     105           5     Monitor    1400\n",
      "\n",
      "Shape of customer data: (100, 3)\n",
      "Shape of sales data: (400, 4)\n",
      "\n",
      "Missing values in customer data:\n",
      "CustomerID    0\n",
      "Age           0\n",
      "City          1\n",
      "dtype: int64\n",
      "\n",
      "Missing values in sales data:\n",
      "SaleID        0\n",
      "CustomerID    0\n",
      "Product       0\n",
      "Amount        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in customer data after handling:\n",
      "CustomerID    0\n",
      "Age           0\n",
      "City          0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in sales data after handling:\n",
      "SaleID        0\n",
      "CustomerID    0\n",
      "Product       0\n",
      "Amount        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1reh\\AppData\\Local\\Temp\\ipykernel_15384\\617163605.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customer_data['CustomerID'].fillna(0, inplace=True)\n",
      "C:\\Users\\a1reh\\AppData\\Local\\Temp\\ipykernel_15384\\617163605.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customer_data['Age'].fillna(customer_data['Age'].mean(), inplace=True)\n",
      "C:\\Users\\a1reh\\AppData\\Local\\Temp\\ipykernel_15384\\617163605.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  customer_data['City'].fillna(customer_data['City'].mode().iloc[0], inplace=True)  # Replace missing values in 'missing_column' with 0\n",
      "C:\\Users\\a1reh\\AppData\\Local\\Temp\\ipykernel_15384\\617163605.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sales_data['SaleID'].fillna(0, inplace=True)  # Replace missing values in 'missing_column' with mean\n",
      "C:\\Users\\a1reh\\AppData\\Local\\Temp\\ipykernel_15384\\617163605.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sales_data['CustomerID'].fillna(random.choice(customer_data[\"CustomerID\"]),inplace=True)\n",
      "C:\\Users\\a1reh\\AppData\\Local\\Temp\\ipykernel_15384\\617163605.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  sales_data['Product'].fillna(sales_data[\"Product\"].mode().iloc[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load the datasets\n",
    "customer_data = pd.read_csv(\"customers.csv\")\n",
    "sales_data = pd.read_csv(\"sales.csv\")\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"First few rows of customer data:\")\n",
    "print(customer_data.head())\n",
    "print(\"\\nFirst few rows of sales data:\")\n",
    "print(sales_data.head())\n",
    "\n",
    "# Show the total number of rows and columns\n",
    "print(\"\\nShape of customer data:\", customer_data.shape)\n",
    "print(\"Shape of sales data:\", sales_data.shape)\n",
    "\n",
    "missing_customers = customer_data.isnull().sum()\n",
    "# Check for missing values and handle them\n",
    "print(\"\\nMissing values in customer data:\")\n",
    "print(missing_customers)\n",
    "\n",
    "missing_sales = sales_data.isnull().sum()\n",
    "print(\"\\nMissing values in sales data:\")\n",
    "print(missing_sales)\n",
    "\n",
    "if not missing_customers.empty:\n",
    "    customer_data['CustomerID'].fillna(0, inplace=True)\n",
    "    customer_data['Age'].fillna(customer_data['Age'].mean(), inplace=True)\n",
    "    customer_data['City'].fillna(customer_data['City'].mode().iloc[0], inplace=True)  # Replace missing values in 'missing_column' with 0\n",
    "    sales_data['SaleID'].fillna(0, inplace=True)  # Replace missing values in 'missing_column' with mean\n",
    "\n",
    "if not missing_sales.empty:\n",
    "    sales_data['CustomerID'].fillna(random.choice(customer_data[\"CustomerID\"]),inplace=True)\n",
    "    sales_data['Product'].fillna(sales_data[\"Product\"].mode().iloc[0], inplace=True)\n",
    "    missing_row = sales_data[sales_data[\"Amount\"].isnull()]\n",
    "    if not missing_row.empty:\n",
    "        missing_product = missing_row['Product'].values[0]\n",
    "        similar_rows = sales_data[(sales_data['Product'] == missing_product) & sales_data['Amount'].notnull()]\n",
    "        imputed_amount = similar_rows['Amount'].mode().iloc[0]\n",
    "        sales_data['Amount'].fillna(imputed_amount,inplace=True)\n",
    "\n",
    "# Verify if missing values are handled\n",
    "print(\"\\nMissing values in customer data after handling:\")\n",
    "print(customer_data.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in sales data after handling:\")\n",
    "print(sales_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 \n",
    "Using the `customers.csv` file, convert its data into a Python dictionary. Use the dictionary to filter customers from a specific city. Repeat the operation using a DataFrame and compare the efficiency of both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary approach time: 0.0010106563568115234 seconds\n",
      "DataFrame approach time: 0.0017287731170654297 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 1. Converting CSV to Dictionary\n",
    "def convert_to_dict(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = f.readlines()\n",
    "        header = data[0].strip().split(',')\n",
    "        customer_dict = {}\n",
    "        for line in data[1:]:\n",
    "            row = line.strip().split(',')\n",
    "            customer = dict(zip(header, row))\n",
    "            customer_dict[customer['CustomerID']] = customer\n",
    "    return customer_dict\n",
    "\n",
    "# 2. Filtering Customers with Dictionary\n",
    "def filter_by_city_dict(customer_dict, city):\n",
    "    filtered_customers = [customer for customer in customer_dict.values() if customer['City'] == city]\n",
    "    return filtered_customers\n",
    "\n",
    "# 3. Converting to DataFrame\n",
    "def convert_to_dataframe(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# 4. Filtering Customers with DataFrame\n",
    "def filter_by_city_df(df, city):\n",
    "    filtered_df = df[df['City'] == city]\n",
    "    return filtered_df\n",
    "\n",
    "# 5. Comparing Efficiency\n",
    "def compare_efficiency(file_path, city):\n",
    "    start_time_dict = time.time()\n",
    "    customer_dict = convert_to_dict(file_path)\n",
    "    filtered_customers_dict = filter_by_city_dict(customer_dict, city)\n",
    "    end_time_dict = time.time()\n",
    "    dict_time = end_time_dict - start_time_dict\n",
    "\n",
    "    start_time_df = time.time()\n",
    "    df = convert_to_dataframe(file_path)\n",
    "    filtered_df = filter_by_city_df(df, city)\n",
    "    end_time_df = time.time()\n",
    "    df_time = end_time_df - start_time_df\n",
    "\n",
    "    print(\"Dictionary approach time:\", dict_time, \"seconds\")\n",
    "    print(\"DataFrame approach time:\", df_time, \"seconds\")\n",
    "\n",
    "# Example Usage\n",
    "file_path = \"customers.csv\"\n",
    "city = \"New York\"\n",
    "\n",
    "compare_efficiency(file_path, city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 \n",
    "Identify duplicate rows, if any, in the datasets. Remove these duplicates to ensure clean data. After cleaning, verify that there are no duplicates left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows in Customers: 0\n",
      "Number of duplicate rows in Sales: 0\n",
      "Number of duplicate rows in cleaned Customers: 0\n",
      "Number of duplicate rows in cleaned Sales: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df_customers = pd.read_csv('customers.csv')\n",
    "df_sales = pd.read_csv('sales.csv')\n",
    "# Identify duplicate rows\n",
    "duplicates_customers = df_customers.duplicated()\n",
    "duplicates_sales = df_sales.duplicated()\n",
    "\n",
    "# Print the number of duplicate rows\n",
    "print(\"Number of duplicate rows in Customers:\", duplicates_customers.sum())\n",
    "print(\"Number of duplicate rows in Sales:\", duplicates_sales.sum())\n",
    "\n",
    "# Remove duplicate rows\n",
    "df_cleaned_customers = df_customers.drop_duplicates()\n",
    "df_cleaned_sales = df_sales.drop_duplicates()\n",
    "# Verify that there are no more duplicates\n",
    "print(\"Number of duplicate rows in cleaned Customers:\", df_cleaned_customers.duplicated().sum())\n",
    "print(\"Number of duplicate rows in cleaned Sales:\", df_cleaned_sales.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 \n",
    "Create a new column in the ```sales.csv``` data that reflects the total amount after applying a `10%` discount on the `Amount` column. Group the data by `Product` and calculate the total sales for each product. Present the results in a well-structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Product  Discounted_Amount\n",
      "0  Headphones            79200.0\n",
      "1      Laptop            14400.0\n",
      "2     Monitor           100800.0\n",
      "3  Smartphone            36000.0\n",
      "4      Tablet            57600.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "sales_data = pd.read_csv('sales.csv')\n",
    "\n",
    "# Create a new column for discounted amount\n",
    "sales_data['Discounted_Amount'] = sales_data['Amount'] * 0.9\n",
    "\n",
    "# Group the data by product and calculate total sales\n",
    "total_sales_by_product = sales_data.groupby('Product')['Discounted_Amount'].sum().reset_index()\n",
    "\n",
    "# Print the results in a structured format\n",
    "print(total_sales_by_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 \n",
    "Filter the data in the `customers.csv` file to retain only those customers whose age falls in the range of `25` to `35`. Save the filtered data in a new structure and analyze how many customers belong to each city within this age range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\n",
      "Houston        11\n",
      "Phoenix         8\n",
      "New York        7\n",
      "Los Angeles     7\n",
      "Chicago         7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "customers_data = pd.read_csv('customers.csv')\n",
    "\n",
    "# Filter customers by age range\n",
    "filtered_customers = customers_data[(customers_data['Age'] >= 25) & (customers_data['Age'] <= 35)]\n",
    "\n",
    "# Analyze customers by city\n",
    "city_counts = filtered_customers['City'].value_counts()\n",
    "\n",
    "print(city_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 \n",
    "Merge the `customers.csv` and `sales.csv` datasets on `CustomerID`. From the merged dataset: \n",
    "* Identify the city that generated the highest total sales. \n",
    "* Find the product with the most units sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SaleID  CustomerID     Product  Amount  Age         City\n",
      "0       101           1      Laptop     200   22     New York\n",
      "1       102           2  Smartphone     500   23  Los Angeles\n",
      "2       103           3      Tablet     800   24      Chicago\n",
      "3       104           4  Headphones    1100   25      Houston\n",
      "4       105           5     Monitor    1400   26      Phoenix\n",
      "..      ...         ...         ...     ...  ...          ...\n",
      "395     496          96      Laptop     200   27     New York\n",
      "396     497          97  Smartphone     500   28  Los Angeles\n",
      "397     498          98      Tablet     800   29      Chicago\n",
      "398     499          99  Headphones    1100   30      Houston\n",
      "399     500         100     Monitor    1400   31      Phoenix\n",
      "\n",
      "[400 rows x 6 columns]\n",
      "City with highest sales: Phoenix\n",
      "Product with most units sold: Laptop\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "customers_data = pd.read_csv('customers.csv')\n",
    "sales_data = pd.read_csv('sales.csv')\n",
    "\n",
    "# Merge the datasets on the 'CustomerID' column\n",
    "merged_data = pd.merge(sales_data, customers_data, on='CustomerID')\n",
    "print(merged_data)\n",
    "# Calculate total sales by city\n",
    "total_sales_by_city = merged_data.groupby('City')['Amount'].sum().reset_index()\n",
    "city_with_highest_sales = total_sales_by_city.loc[total_sales_by_city['Amount'].idxmax()]['City']\n",
    "print(\"City with highest sales:\", city_with_highest_sales)\n",
    "\n",
    "# Find the product with the most units sold\n",
    "product_with_most_sales = merged_data['Product'].value_counts().idxmax()\n",
    "print(\"Product with most units sold:\", product_with_most_sales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
